#!/usr/bin/env python

import json
import os
import sys
import time
from argparse import ArgumentParser

import pandas as pd
import yaml
from tabulate import tabulate
from git import Repo
import giturlparse as gup

from tagpack import __version__ as version
from tagpack.cmd_utils import print_line, print_info, print_fail, print_success
from tagpack.graphsense import GraphSense
from tagpack.tagpack import TagPack, TagPackFileError, collect_tagpack_files
from tagpack.tagpack_schema import TagPackSchema, ValidationError
from tagpack.tagstore import TagStore
from tagpack.taxonomy import Taxonomy

CONFIG_FILE = "config.yaml"

TAXONOMY_URL = 'https://graphsense.github.io'

DEFAULT_CONFIG = {
    'taxonomies': {
        'entity': f'{TAXONOMY_URL}/DW-VA-Taxonomy/assets/data/entities.csv',
        'abuse': f'{TAXONOMY_URL}/DW-VA-Taxonomy/assets/data/abuses.csv'
    }
}


_DEFAULT_SCHEMA = "tagstore"


def _remote_load_taxonomies(config):
    if 'taxonomies' not in config:
        return None
    taxonomies = {}
    for key in config['taxonomies']:
        taxonomy = _remote_load_taxonomy(config, key)
        taxonomies[key] = taxonomy
    return taxonomies


def _remote_load_taxonomy(config, key):
    if 'taxonomies' not in config:
        return None
    uri = config['taxonomies'][key]
    taxonomy = Taxonomy(key, uri)
    taxonomy.load_from_remote()
    return taxonomy


def list_taxonomies(args=None):
    config = _load_config(args.config)

    print_line("Show configured taxonomies")
    print_line(f"Configuration: {args.config}", 'info')
    count = 0
    if 'taxonomies' not in config:
        print_line("No configured taxonomies", 'fail')
    else:
        for key, value in config['taxonomies'].items():
            print_line(value)
            count += 1
        print_line(f"{count} configured taxonomies", 'success')


def show_taxonomy_concepts(args):
    config = _load_config(args.config)

    if 'taxonomies' not in config:
        print_line("No taxonomies configured", 'fail')
        return
    print_line("Showing concepts of taxonomy {}".format(args.taxonomy))
    print("Remote URI: ", config['taxonomies'][args.taxonomy], "\n")
    taxonomy = _remote_load_taxonomy(config, args.taxonomy)
    if args.verbose:
        headers = ['Id', 'Label', 'Uri', 'Description']
        table = [[c.id, c.label, c.uri, c.description]
                 for c in taxonomy.concepts]
    else:
        headers = ['Id', 'Label']
        table = [[c.id, c.label] for c in taxonomy.concepts]

    print(tabulate(table, headers=headers))
    print_line(f"{len(taxonomy.concepts)} taxonomy concepts", 'success')


def insert_taxonomy(args):
    config = _load_config(args.config)

    if 'taxonomies' not in config:
        print_line("No taxonomies configured", 'fail')
        return

    tax_keys = [args.taxonomy]

    if not args.taxonomy:  # insert all available taxonomies
        tax_keys = config['taxonomies'].keys()

    t0 = time.time()
    print_line("Taxonomy insert starts")

    tagstore = TagStore(args.url, args.schema)

    for t in tax_keys:
        print(f"Taxonomy: {t}")
        try:
            taxonomy = _remote_load_taxonomy(config, t)
            tagstore.insert_taxonomy(taxonomy)

            print(f"{taxonomy.key} | {taxonomy.uri}:", end=' ')
            print_success("INSERTED")

            duration = round(time.time() - t0, 2)
            print_line(
                f"Inserted {len(taxonomy.concepts)} concepts in {duration}s",
                'success')
        except Exception as e:
            print_fail(e)
            print_line("Aborted insert", 'fail')


def _load_config(cfile):
    if not os.path.isfile(cfile):
        print_line(
            "Could not find TagPack repository configuration file.", 'fail')
        print_info(f"Creating a new default configuration file: {cfile}")
        with open('config.yaml', 'a') as the_file:
            yaml.dump(DEFAULT_CONFIG, the_file, allow_unicode=True)
    return yaml.safe_load(open(cfile, 'r'))


def show_config(args):
    print("Config File:", args.config)
    if args.verbose:
        list_taxonomies()


def validate_tagpack(args):
    config = _load_config(args.config)

    t0 = time.time()
    print_line("TagPack validation starts")
    print(f"Path: {args.path}")

    taxonomies = _remote_load_taxonomies(config)
    taxonomy_keys = [key for key in taxonomies.keys()]
    print(f"Loaded taxonomies: {taxonomy_keys}")

    schema = TagPackSchema()
    print(f"Loaded schema: {schema.definition}")

    tagpack_files, headerfile_dir = collect_tagpack_files(args.path)
    print_info(f"Collected {len(tagpack_files)} TagPack files\n")

    no_passed = 0
    try:
        for tagpack_file in tagpack_files:
            tagpack = TagPack.load_from_file('', tagpack_file,
                                             schema, taxonomies, headerfile_dir)

            print(f'{tagpack_file}: ', end='')

            tagpack.validate()
            print_success("PASSED")
            no_passed += 1
    except (ValidationError, TagPackFileError) as e:
        print_fail("FAILED", e)

    status = 'fail' if no_passed < len(tagpack_files) else 'success'

    duration = round(time.time() - t0, 2)
    print_line("{}/{} TagPacks passed in {}s"
               .format(no_passed, len(tagpack_files), duration), status)


def _get_repository_and_subpath(path: str) -> (Repo, str):
    """ Parse '/home/anna/graphsense/graphsense-tagpacks/public/packs' ->
        and return a tuple (Repo, 'public/packs')
     """
    repo_path = path
    while repo_path != os.path.sep:
        try:
            rel_path = os.path.dirname(path.replace(repo_path, ''))
            return Repo(repo_path), rel_path[1:]
        except:
            pass
        repo_path, _ = os.path.split(repo_path)
    return None, None


def _get_remote_uri(path, strict_check, no_git):
    """ For a given path string
    '/home/anna/graphsense/graphsense-tagpacks/public/packs'

    return remote URI
        'https://github.com/anna/tagpacks/blob/develop/public/packs/'
    or, if no_git is set
        path

    Local git copy will be checked for modifications by default.
    Toggle strict_check param to change this.

    If path does not contain git information, the original path
    is returned.
    """
    if no_git:
        if os.path.isfile:
            return os.path.dirname(path)
        return path

    repo, rel_path = _get_repository_and_subpath(path)
    if not repo:
        print_info(f"No repository root found in {path}.")
        return path

    if strict_check and repo.is_dirty():
        print_info(f"Local modifications in {repo.common_dir} detected, please push first.")
        sys.exit(0)

    if len(repo.remotes) > 1:
        print_info("Multiple remotes present, cannot decide on backlink. ")
        sys.exit(0)

    u = next(repo.remotes[0].urls)
    g = gup.parse(u).url2https.replace('.git', '')
    return f'{g}/tree/{repo.active_branch.name}/{rel_path}'


def insert_tagpack(args):
    config = _load_config(args.config)

    t0 = time.time()
    print_line("TagPack insert starts")
    print(f"Path: {args.path}")

    base_url = _get_remote_uri(args.path, not args.no_strict_check, args.no_git)

    tagstore = TagStore(args.url, args.schema)

    schema = TagPackSchema()
    print_info(f"Loaded TagPack schema definition: {schema.definition}")

    taxonomies = _remote_load_taxonomies(config)
    taxonomy_keys = [key for key in taxonomies.keys()]
    print(f"Loaded taxonomies: {taxonomy_keys}")

    tagpack_files, headerfile_dir = collect_tagpack_files(args.path)
    if args.add_new:
        print_info("Checking which files are new to the tagstore:")
        existing = tagstore.get_ingested_tagpacks()
        tagpack_files = [x for x in tagpack_files if os.path.basename(x) not in existing]

    print_info(f"Collected {len(tagpack_files)} TagPack files\n")

    no_passed = 0
    no_tags = 0
    for i, tagpack_file in enumerate(tagpack_files, start=1):
        tagpack = TagPack.load_from_file(base_url, tagpack_file,
                                         schema, taxonomies, headerfile_dir)

        print(f'{i} {tagpack_file}: ', end='')
        try:
            tagstore.insert_tagpack(tagpack, args.public, args.force)
            print_success(f"PROCESSED {len(tagpack.tags)} Tags")
            no_passed += 1
            no_tags = no_tags + len(tagpack.tags)
        except Exception as e:
            print_fail("FAILED", e)

    status = 'fail' if no_passed < len(tagpack_files) else 'success'

    duration = round(time.time() - t0, 2)
    print_line("Processed {}/{} TagPacks with {} Tags in {}s. Only tags for supported currencies {} are inserted."
               .format(no_passed, len(tagpack_files), no_tags, duration, tagstore.supported_currencies),
               status)


def _split_into_chunks(seq, size):
    return (seq[pos:pos + size] for pos in range(0, len(seq), size))


def insert_cluster_mapping(args, batch_size=5_000):
    tagstore = TagStore(args.url, args.schema)
    df = pd.DataFrame(tagstore.get_addresses(args.update), columns=['address', 'currency'])

    ks_mapping = json.load(open(args.ks_file))
    gs = GraphSense(args.db_nodes, ks_mapping)

    processed_currencies = []
    t0 = time.time()
    for currency, data in df.groupby('currency'):
        if gs.contains_keyspace_mapping(currency):
            try:
                print(currency)
                mappings_count = 0
                for batch in _split_into_chunks(data, batch_size):
                    clusters = gs.get_address_clusters(batch, currency)
                    clusters['currency'] = currency
                    tagstore.insert_cluster_mappings(clusters)
                    mappings_count += len(clusters)

                print_success(f"INSERTED/UPDATED {mappings_count} {currency} cluster mappings")
                processed_currencies.append(currency)
            except Exception as e:
                print_fail("FAILED", e)

    duration = round(time.time() - t0, 2)
    print_line(f"Inserted {'missing' if not args.update else 'all'} cluster mappings for {processed_currencies} in {duration}s", "success")
    tagstore.finish_mappings_update(gs.ks_map.keys())


def update_db(args):
    tagstore = TagStore(args.url, args.schema)
    tagstore.refresh_db()


def show_version():
    return "GraphSense TagPack management tool v" + version


def main():
    parser = ArgumentParser(
        description='GraphSense TagPack validation and ingest tool',
        epilog='GraphSense TagPack Tool v{} - https://graphsense.info'
        .format(version))
    parser.add_argument('-v', '--version', action='version',
                        version=show_version())
    parser.add_argument('--config', help='path to config.yaml',
                        default=os.path.join(os.getcwd(), CONFIG_FILE))

    subparsers = parser.add_subparsers(title='Commands')

    # parser for taxonomy command
    parser_t = subparsers.add_parser("taxonomy",
                                     help="show taxonomy concepts")
    parser_t.set_defaults(func=list_taxonomies)

    parser_t_subparsers = parser_t.add_subparsers(title='Taxonomy commands')

    # parser for taxonomy insert command
    parser_t_i = parser_t_subparsers.add_parser(
        'insert', help='insert taxonomy into GraphSense')
    parser_t_i.add_argument('taxonomy', metavar='TAXONOMY_KEY', nargs='?',
                            help='the selected taxonomy', default=None)
    parser_t_i.add_argument('--schema',
                            default=_DEFAULT_SCHEMA, metavar='DB_SCHEMA',
                            help="PostgreSQL schema for taxonomy tables")
    parser_t_i.add_argument('-u', '--url', help="postgresql://user:password@db_host:port/database")
    parser_t_i.set_defaults(func=insert_taxonomy)

    # parser for taxonomy show command
    parser_t_s = parser_t_subparsers.add_parser(
        'show', help='show taxonomy concepts')
    parser_t_s.add_argument('taxonomy', metavar='TAXONOMY_KEY',
                            help='the selected taxonomy')
    parser_t_s.add_argument('-v', '--verbose', action='store_true',
                            help="verbose concepts")
    parser_t_s.set_defaults(func=show_taxonomy_concepts)

    # parser for config command
    parser_c = subparsers.add_parser("config",
                                     help="show TagPack Repository config")
    parser_c.add_argument('-v', '--verbose', action='store_true',
                          help='verbose configuration')
    parser_c.set_defaults(func=show_config)

    # parser for insert command
    parser_i = subparsers.add_parser("insert",
                                     help="insert TagPacks into GraphSense")
    parser_i.add_argument('path', nargs='?', metavar='PATH',
                          default=os.getcwd(),
                          help='TagPacks file or folder root path')
    parser_i.add_argument('--schema',
                          default=_DEFAULT_SCHEMA, metavar='DB_SCHEMA',
                          help="PostgreSQL schema for tagpack tables")
    parser_i.add_argument('-u', '--url', help="postgresql://user:password@db_host:port/database")
    parser_i.add_argument('-b', '--batch_size', nargs='?', type=int,
                          default=1000,
                          help='batch size for insert)')
    parser_i.add_argument("--public", action='store_true',
                        help='By default, tagpacks are declared private in the database. '
                             'Use this switch to declare them public.')
    parser_i.add_argument("--force", action='store_true',
                          help='By default, tagpack insertion stops when an already ingested tagpack'
                               'exists in the database. Use this switch to force re-insertion.')
    parser_i.add_argument("--add_new", action='store_true',
                          help='By default, tagpack insertion stops when an already ingested tagpack'
                               'exists in the database. Use this switch to ingest new tagpacks '
                               'while skipping over existing ones.')
    parser_i.add_argument("--no_strict_check", action='store_true',
                          help='Disables check for local modifications in git repository')
    parser_i.add_argument("--no_git", action='store_true',
                          help='Disables check for local git repository')
    parser_i.set_defaults(func=insert_tagpack)

    # parser for validate command
    parser_v = subparsers.add_parser("validate", help="validate TagPacks")
    parser_v.add_argument('path', nargs='?', metavar='PATH',
                          default=[os.getcwd()],
                          help='TagPacks file or folder root path')
    parser_v.set_defaults(func=validate_tagpack)

    # parser for cluster command
    parser_cl = subparsers.add_parser("cluster",
                                     help="insert cluster mappings")
    parser_cl.add_argument('-d', '--db_nodes', nargs='+',
                          default=['localhost'], metavar='DB_NODE',
                          help='Cassandra node(s); default "localhost")')
    parser_cl.add_argument('-f', '--ks_file',
                          metavar='KEYSPACE_FILE',
                          help="JSON file with Cassandra keyspaces that contain GraphSense cluster mappings")
    parser_cl.add_argument('--schema',
                          default=_DEFAULT_SCHEMA, metavar='DB_SCHEMA',
                          help="PostgreSQL schema for GraphSense cluster mapping table")
    parser_cl.add_argument('-u', '--url', help="postgresql://user:password@db_host:port/database")
    parser_cl.add_argument('--update', help='update  all cluster mappings', action='store_true')
    parser_cl.set_defaults(update=False)
    parser_cl.set_defaults(func=insert_cluster_mapping)

    # parser for database statistics refresh
    parser_db = subparsers.add_parser("db",
                            help="refresh database statistics")
    parser_db.add_argument('--schema',
                           default=_DEFAULT_SCHEMA, metavar='DB_SCHEMA',
                           help="PostgreSQL schema for GraphSense cluster mapping table")
    parser_db.add_argument('-u', '--url', help="postgresql://user:password@db_host:port/database")
    parser_db.set_defaults(func=update_db)

    if len(sys.argv) == 1:
        parser.print_help(sys.stderr)
        sys.exit(1)

    args = parser.parse_args()
    args.func(args)


if __name__ == '__main__':
    if sys.version_info < (3, 6):
        sys.exit("This program requires python version 3.6 or later")
    main()
